{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7405b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (75.1.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: wheel in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (0.44.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.44.0\n",
      "    Uninstalling wheel-0.44.0:\n",
      "      Successfully uninstalled wheel-0.44.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.1.0\n",
      "    Uninstalling setuptools-75.1.0:\n",
      "      Successfully uninstalled setuptools-75.1.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.0.1 setuptools-75.3.2 wheel-0.45.1\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting certifi>=14.05.14 (from kaggle)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset-normalizer (from kaggle)\n",
      "  Downloading charset_normalizer-3.4.2-cp38-cp38-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna (from kaggle)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting protobuf (from kaggle)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (from kaggle) (2.9.0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting requests (from kaggle)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (from kaggle) (75.3.2)\n",
      "Requirement already satisfied: six>=1.10 in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (from kaggle) (1.16.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting urllib3>=1.15.1 (from kaggle)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting webencodings (from kaggle)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp38-cp38-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, protobuf, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
      "Successfully installed bleach-6.1.0 certifi-2025.7.14 charset-normalizer-3.4.2 idna-3.10 kaggle-1.7.4.5 protobuf-5.29.5 python-slugify-8.0.4 requests-2.32.4 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.2.3 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c4286bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eeaaa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
      "License(s): GPL-2.0\n",
      "Downloading asl-alphabet.zip to data\n",
      "100%|█████████████████████████████████████▉| 1.02G/1.03G [00:00<00:00, 3.23GB/s]\n",
      "100%|██████████████████████████████████████| 1.03G/1.03G [00:00<00:00, 3.30GB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "!kaggle datasets download -d grassknoted/asl-alphabet -p data --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fff9aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Directory: data\n",
      " Subfolders: ['asl_alphabet_test', 'asl_alphabet_train']\n",
      "\n",
      "Directory: data/asl_alphabet_test\n",
      " Subfolders: ['asl_alphabet_test']\n",
      "\n",
      "Directory: data/asl_alphabet_test/asl_alphabet_test\n",
      " Files (first 10): ['F_test.jpg', 'G_test.jpg', 'L_test.jpg', 'M_test.jpg', 'R_test.jpg', 'S_test.jpg', 'X_test.jpg', 'Y_test.jpg', 'U_test.jpg', 'T_test.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train\n",
      " Subfolders: ['asl_alphabet_train']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train\n",
      " Subfolders: ['R', 'U', 'I', 'N', 'G', 'Z', 'T', 'S', 'A', 'F', 'O', 'H', 'del', 'nothing', 'space', 'M', 'J', 'C', 'D', 'V', 'Q', 'X', 'E', 'B', 'K', 'L', 'Y', 'P', 'W']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/R\n",
      " Files (first 10): ['R2837.jpg', 'R2189.jpg', 'R1480.jpg', 'R1494.jpg', 'R2823.jpg', 'R228.jpg', 'R200.jpg', 'R566.jpg', 'R572.jpg', 'R214.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/U\n",
      " Files (first 10): ['U553.jpg', 'U1601.jpg', 'U2308.jpg', 'U1167.jpg', 'U235.jpg', 'U221.jpg', 'U1173.jpg', 'U1615.jpg', 'U547.jpg', 'U2334.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/I\n",
      " Files (first 10): ['I1831.jpg', 'I522.jpg', 'I244.jpg', 'I2486.jpg', 'I250.jpg', 'I2492.jpg', 'I536.jpg', 'I1825.jpg', 'I278.jpg', 'I1819.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/N\n",
      " Files (first 10): ['N2607.jpg', 'N2161.jpg', 'N1468.jpg', 'N2175.jpg', 'N2613.jpg', 'N259.jpg', 'N271.jpg', 'N1332.jpg', 'N1454.jpg', 'N517.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/G\n",
      " Files (first 10): ['G2572.jpg', 'G269.jpg', 'G2214.jpg', 'G2200.jpg', 'G1709.jpg', 'G2566.jpg', 'G533.jpg', 'G1047.jpg', 'G2228.jpg', 'G1721.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/Z\n",
      " Files (first 10): ['Z2951.jpg', 'Z660.jpg', 'Z2789.jpg', 'Z1280.jpg', 'Z106.jpg', 'Z112.jpg', 'Z1294.jpg', 'Z2945.jpg', 'Z674.jpg', 'Z884.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/T\n",
      " Files (first 10): ['T1412.jpg', 'T895.jpg', 'T1374.jpg', 'T1360.jpg', 'T2669.jpg', 'T659.jpg', 'T881.jpg', 'T1406.jpg', 'T2127.jpg', 'T671.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/S\n",
      " Files (first 10): ['S122.jpg', 'S644.jpg', 'S1693.jpg', 'S888.jpg', 'S650.jpg', 'S1687.jpg', 'S136.jpg', 'S1877.jpg', 'S678.jpg', 'S1863.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/A\n",
      " Files (first 10): ['A25.jpg', 'A2286.jpg', 'A1957.jpg', 'A618.jpg', 'A1943.jpg', 'A31.jpg', 'A2292.jpg', 'A142.jpg', 'A19.jpg', 'A624.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/F\n",
      " Files (first 10): ['F2761.jpg', 'F1268.jpg', 'F611.jpg', 'F177.jpg', 'F43.jpg', 'F2007.jpg', 'F2013.jpg', 'F57.jpg', 'F163.jpg', 'F605.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/O\n",
      " Files (first 10): ['O2414.jpg', 'O153.jpg', 'O635.jpg', 'O2372.jpg', 'O621.jpg', 'O2366.jpg', 'O2400.jpg', 'O147.jpg', 'O1109.jpg', 'O2428.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/H\n",
      " Files (first 10): ['H2695.jpg', 'H1388.jpg', 'H2681.jpg', 'H2859.jpg', 'H628.jpg', 'H600.jpg', 'H2871.jpg', 'H166.jpg', 'H2865.jpg', 'H172.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/del\n",
      " Files (first 10): ['del1308.jpg', 'del574.jpg', 'del2601.jpg', 'del2167.jpg', 'del212.jpg', 'del2173.jpg', 'del206.jpg', 'del560.jpg', 'del2615.jpg', 'del548.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/nothing\n",
      " Files (first 10): ['nothing143.jpg', 'nothing2774.jpg', 'nothing2012.jpg', 'nothing625.jpg', 'nothing2006.jpg', 'nothing631.jpg', 'nothing1269.jpg', 'nothing157.jpg', 'nothing2760.jpg', 'nothing1241.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/space\n",
      " Files (first 10): ['space950.jpg', 'space788.jpg', 'space2.jpg', 'space2909.jpg', 'space944.jpg', 'space1596.jpg', 'space2921.jpg', 'space2935.jpg', 'space978.jpg', 'space1582.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/M\n",
      " Files (first 10): ['M744.jpg', 'M2908.jpg', 'M750.jpg', 'M988.jpg', 'M2920.jpg', 'M778.jpg', 'M1597.jpg', 'M1583.jpg', 'M2934.jpg', 'M2707.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/J\n",
      " Files (first 10): ['J2223.jpg', 'J2545.jpg', 'J995.jpg', 'J981.jpg', 'J1058.jpg', 'J759.jpg', 'J2551.jpg', 'J2237.jpg', 'J1716.jpg', 'J771.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/C\n",
      " Files (first 10): ['C769.jpg', 'C2156.jpg', 'C1339.jpg', 'C2630.jpg', 'C8.jpg', 'C2624.jpg', 'C2142.jpg', 'C1463.jpg', 'C755.jpg', 'C1305.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/D\n",
      " Files (first 10): ['D1806.jpg', 'D760.jpg', 'D774.jpg', 'D1812.jpg', 'D1184.jpg', 'D984.jpg', 'D748.jpg', 'D990.jpg', 'D2499.jpg', 'D1190.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/V\n",
      " Files (first 10): ['V14.jpg', 'V728.jpg', 'V28.jpg', 'V1926.jpg', 'V1098.jpg', 'V700.jpg', 'V2591.jpg', 'V714.jpg', 'V2585.jpg', 'V1932.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/Q\n",
      " Files (first 10): ['Q1225.jpg', 'Q735.jpg', 'Q72.jpg', 'Q1543.jpg', 'Q1557.jpg', 'Q66.jpg', 'Q721.jpg', 'Q2738.jpg', 'Q1231.jpg', 'Q709.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/X\n",
      " Files (first 10): ['X2459.jpg', 'X1150.jpg', 'X711.jpg', 'X1636.jpg', 'X705.jpg', 'X1622.jpg', 'X1144.jpg', 'X2465.jpg', 'X2303.jpg', 'X739.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/E\n",
      " Files (first 10): ['E318.jpg', 'E1397.jpg', 'E324.jpg', 'E2846.jpg', 'E442.jpg', 'E456.jpg', 'E330.jpg', 'E2852.jpg', 'E1383.jpg', 'E1368.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/B\n",
      " Files (first 10): ['B477.jpg', 'B2345.jpg', 'B1894.jpg', 'B2423.jpg', 'B311.jpg', 'B2437.jpg', 'B305.jpg', 'B1658.jpg', 'B1880.jpg', 'B463.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/K\n",
      " Files (first 10): ['K1539.jpg', 'K335.jpg', 'K2030.jpg', 'K2756.jpg', 'K453.jpg', 'K447.jpg', 'K2742.jpg', 'K2024.jpg', 'K321.jpg', 'K1505.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/L\n",
      " Files (first 10): ['L1960.jpg', 'L328.jpg', 'L1974.jpg', 'L466.jpg', 'L300.jpg', 'L1784.jpg', 'L2299.jpg', 'L314.jpg', 'L1790.jpg', 'L1948.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/Y\n",
      " Files (first 10): ['Y2892.jpg', 'Y369.jpg', 'Y1343.jpg', 'Y1425.jpg', 'Y2138.jpg', 'Y1431.jpg', 'Y1357.jpg', 'Y2886.jpg', 'Y355.jpg', 'Y2676.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/P\n",
      " Files (first 10): ['P1036.jpg', 'P2259.jpg', 'P1988.jpg', 'P1750.jpg', 'P1744.jpg', 'P359.jpg', 'P1022.jpg', 'P2503.jpg', 'P417.jpg', 'P371.jpg']\n",
      "\n",
      "Directory: data/asl_alphabet_train/asl_alphabet_train/W\n",
      " Files (first 10): ['W344.jpg', 'W2966.jpg', 'W422.jpg', 'W2972.jpg', 'W436.jpg', 'W350.jpg', 'W378.jpg', 'W2782.jpg', 'W2796.jpg', 'W387.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the contents of your `data/` folder\n",
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"data\"):\n",
    "    print(f\"\\nDirectory: {root}\")\n",
    "    if dirs:\n",
    "        print(\" Subfolders:\", dirs)\n",
    "    if files:\n",
    "        print(\" Files (first 10):\", files[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "656cec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752633901.328267  591779 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84000 images across 28 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting landmarks:   0%|          | 0/84000 [00:00<?, ?it/s]W0000 00:00:1752633901.335388  902297 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1752633901.344589  902299 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "Extracting landmarks: 100%|██████████| 84000/84000 [27:00<00:00, 51.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted landmarks for 63673 images (skipped 20327).\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 3: Extract A–Z plus ‘del’ & ‘space’ landmarks ─────────────────────────\n",
    "\n",
    "import os, cv2, numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = \"data/asl_alphabet_train/asl_alphabet_train\"\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    raise RuntimeError(f\"Train directory not found: {DATA_DIR}\")\n",
    "\n",
    "# Only include A–Z, or exactly 'del' or 'space'\n",
    "valid_labels = set(list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") + [\"del\", \"space\"])\n",
    "\n",
    "all_imgs = []\n",
    "for label in sorted(os.listdir(DATA_DIR)):\n",
    "    if label not in valid_labels:\n",
    "        continue\n",
    "    folder = os.path.join(DATA_DIR, label)\n",
    "    for fn in os.listdir(folder):\n",
    "        if fn.lower().endswith(\".jpg\"):\n",
    "            all_imgs.append((label, os.path.join(folder, fn)))\n",
    "\n",
    "print(f\"Found {len(all_imgs)} images across {len(valid_labels)} classes.\")\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "X, y = [], []\n",
    "for label, img_path in tqdm(all_imgs, desc=\"Extracting landmarks\"):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None: continue\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    res = hands.process(img_rgb)\n",
    "    if not res.multi_hand_landmarks: continue\n",
    "\n",
    "    lm = res.multi_hand_landmarks[0]\n",
    "    coords = []\n",
    "    for p in lm.landmark:\n",
    "        coords += [p.x, p.y, p.z]\n",
    "    X.append(coords)\n",
    "    y.append(label)\n",
    "\n",
    "hands.close()\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y)\n",
    "print(f\"Extracted landmarks for {len(X)} images (skipped {len(all_imgs)-len(X)}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d6d275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (50938, 63) (50938,)\n",
      "Validation set: (12735, 63) (12735,)\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 4: Encode labels & split data ─────────────────────────────────────────\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)  # maps 'A'→0, …, 'Z'→25\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_int,\n",
    "    test_size=0.2,\n",
    "    stratify=y_int,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471bb4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 21:20:22.390637: W tensorflow/core/framework/op_kernel.cc:1857] OP_REQUIRES failed at sparse_xent_op.cc:103 : INVALID_ARGUMENT: Received a label value of 26 which is outside the valid range of [0, 26).  Label values: 7 11 18 8 6 8 21 14 17 12 3 4 19 21 6 4 6 2 16 23 14 10 11 11 12 0 25 26 6 12 24 17\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/var/folders/jw/3zdzttxx32j02g_j4c7wq80c0000gn/T/ipykernel_32379/4086584976.py\", line 17, in <module>\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 61, in train_step\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/losses/losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/ops/nn.py\", line 2000, in sparse_categorical_crossentropy\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 26 which is outside the valid range of [0, 26).  Label values: 7 11 18 8 6 8 21 14 17 12 3 4 19 21 6 4 6 2 16 23 14 10 11 11 12 0 25 26 6 12 24 17\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_239329]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      4\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m63\u001b[39m,)),\n\u001b[1;32m      5\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m26\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m ])\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     12\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/asl3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits defined at (most recent call last):\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n\n  File \"/var/folders/jw/3zdzttxx32j02g_j4c7wq80c0000gn/T/ipykernel_32379/4086584976.py\", line 17, in <module>\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py\", line 61, in train_step\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/trainer.py\", line 383, in _compute_loss\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/trainer.py\", line 351, in compute_loss\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/compile_utils.py\", line 690, in __call__\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/trainers/compile_utils.py\", line 699, in call\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/losses/loss.py\", line 67, in __call__\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/losses/losses.py\", line 33, in call\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/losses/losses.py\", line 2330, in sparse_categorical_crossentropy\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/ops/nn.py\", line 2000, in sparse_categorical_crossentropy\n\n  File \"/Users/ryan/miniconda3/envs/asl3.9/lib/python3.9/site-packages/keras/src/backend/tensorflow/nn.py\", line 753, in sparse_categorical_crossentropy\n\nReceived a label value of 26 which is outside the valid range of [0, 26).  Label values: 7 11 18 8 6 8 21 14 17 12 3 4 19 21 6 4 6 2 16 23 14 10 11 11 12 0 25 26 6 12 24 17\n\t [[{{node compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_multi_step_on_iterator_239329]"
     ]
    }
   ],
   "source": [
    "# ── Cell 5: Build & train the MLP with dynamic output size ────────────────────\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Encode labels and discover number of classes\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)        # maps your strings → integers 0…27\n",
    "num_classes = len(le.classes_)     # should be 28\n",
    "print(\"Classes found:\", le.classes_)\n",
    "\n",
    "# 2) Split into train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_int,\n",
    "    test_size=0.2,\n",
    "    stratify=y_int,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape,   y_val.shape)\n",
    "\n",
    "# 3) Build your MLP with the right number of outputs\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(63,)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 4) Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be15adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: asl_alphabet_mlp.h5  and  label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "model.save(\"asl_alphabet_mlp.h5\")\n",
    "\n",
    "import pickle\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Saved: asl_alphabet_mlp.h5  and  label_encoder.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
