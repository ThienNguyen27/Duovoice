{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7405b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: setuptools in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (75.1.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: wheel in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (0.44.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.44.0\n",
      "    Uninstalling wheel-0.44.0:\n",
      "      Successfully uninstalled wheel-0.44.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.1.0\n",
      "    Uninstalling setuptools-75.1.0:\n",
      "      Successfully uninstalled setuptools-75.1.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.0.1 setuptools-75.3.2 wheel-0.45.1\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.7.4.5-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting certifi>=14.05.14 (from kaggle)\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset-normalizer (from kaggle)\n",
      "  Downloading charset_normalizer-3.4.2-cp38-cp38-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna (from kaggle)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting protobuf (from kaggle)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (from kaggle) (2.9.0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting requests (from kaggle)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (from kaggle) (75.3.2)\n",
      "Requirement already satisfied: six>=1.10 in /Users/ryan/miniconda3/envs/als/lib/python3.8/site-packages (from kaggle) (1.16.0)\n",
      "Collecting text-unidecode (from kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting urllib3>=1.15.1 (from kaggle)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting webencodings (from kaggle)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Downloading kaggle-1.7.4.5-py3-none-any.whl (181 kB)\n",
      "Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp38-cp38-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, protobuf, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
      "Successfully installed bleach-6.1.0 certifi-2025.7.14 charset-normalizer-3.4.2 idna-3.10 kaggle-1.7.4.5 protobuf-5.29.5 python-slugify-8.0.4 requests-2.32.4 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.2.3 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c4286bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/baoph/.kaggle/kaggle.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import stat\n",
    "\n",
    "# 1) Create the .kaggle folder in your home dir (works on Windows too)\n",
    "home = Path.home()\n",
    "kaggle_dir = home / \".kaggle\"\n",
    "kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 2) Move kaggle.json into place\n",
    "src = Path(\"kaggle.json\")\n",
    "dst = kaggle_dir / \"kaggle.json\"\n",
    "if not src.exists():\n",
    "    raise FileNotFoundError(\"Could not find kaggle.json in the current folder\")\n",
    "src.replace(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eeaaa27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
      "Download complete. Files are in C:\\Users\\baoph\\Documents\\Duovoice\\duovoice\\model\\data\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from pathlib import Path\n",
    "\n",
    "# 1) authenticate\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# 2) ensure a local data/ folder exists\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 3) download & unzip\n",
    "api.dataset_download_files(\n",
    "    \"grassknoted/asl-alphabet\",\n",
    "    path=str(data_dir),\n",
    "    unzip=True\n",
    ")\n",
    "print(\"Download complete. Files are in\", data_dir.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fff9aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Directory: data\n",
      " Subfolders: ['asl_alphabet_test', 'asl_alphabet_train']\n",
      "\n",
      "Directory: data\\asl_alphabet_test\n",
      " Subfolders: ['asl_alphabet_test']\n",
      "\n",
      "Directory: data\\asl_alphabet_test\\asl_alphabet_test\n",
      " Files (first 10): ['A_test.jpg', 'B_test.jpg', 'C_test.jpg', 'D_test.jpg', 'E_test.jpg', 'F_test.jpg', 'G_test.jpg', 'H_test.jpg', 'I_test.jpg', 'J_test.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\n",
      " Subfolders: ['asl_alphabet_train']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\n",
      " Subfolders: ['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\A\n",
      " Files (first 10): ['A1.jpg', 'A10.jpg', 'A100.jpg', 'A1000.jpg', 'A1001.jpg', 'A1002.jpg', 'A1003.jpg', 'A1004.jpg', 'A1005.jpg', 'A1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\B\n",
      " Files (first 10): ['B1.jpg', 'B10.jpg', 'B100.jpg', 'B1000.jpg', 'B1001.jpg', 'B1002.jpg', 'B1003.jpg', 'B1004.jpg', 'B1005.jpg', 'B1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\C\n",
      " Files (first 10): ['C1.jpg', 'C10.jpg', 'C100.jpg', 'C1000.jpg', 'C1001.jpg', 'C1002.jpg', 'C1003.jpg', 'C1004.jpg', 'C1005.jpg', 'C1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\D\n",
      " Files (first 10): ['D1.jpg', 'D10.jpg', 'D100.jpg', 'D1000.jpg', 'D1001.jpg', 'D1002.jpg', 'D1003.jpg', 'D1004.jpg', 'D1005.jpg', 'D1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\del\n",
      " Files (first 10): ['del1.jpg', 'del10.jpg', 'del100.jpg', 'del1000.jpg', 'del1001.jpg', 'del1002.jpg', 'del1003.jpg', 'del1004.jpg', 'del1005.jpg', 'del1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\E\n",
      " Files (first 10): ['E1.jpg', 'E10.jpg', 'E100.jpg', 'E1000.jpg', 'E1001.jpg', 'E1002.jpg', 'E1003.jpg', 'E1004.jpg', 'E1005.jpg', 'E1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\F\n",
      " Files (first 10): ['F1.jpg', 'F10.jpg', 'F100.jpg', 'F1000.jpg', 'F1001.jpg', 'F1002.jpg', 'F1003.jpg', 'F1004.jpg', 'F1005.jpg', 'F1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\G\n",
      " Files (first 10): ['G1.jpg', 'G10.jpg', 'G100.jpg', 'G1000.jpg', 'G1001.jpg', 'G1002.jpg', 'G1003.jpg', 'G1004.jpg', 'G1005.jpg', 'G1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\H\n",
      " Files (first 10): ['H1.jpg', 'H10.jpg', 'H100.jpg', 'H1000.jpg', 'H1001.jpg', 'H1002.jpg', 'H1003.jpg', 'H1004.jpg', 'H1005.jpg', 'H1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\I\n",
      " Files (first 10): ['I1.jpg', 'I10.jpg', 'I100.jpg', 'I1000.jpg', 'I1001.jpg', 'I1002.jpg', 'I1003.jpg', 'I1004.jpg', 'I1005.jpg', 'I1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\J\n",
      " Files (first 10): ['J1.jpg', 'J10.jpg', 'J100.jpg', 'J1000.jpg', 'J1001.jpg', 'J1002.jpg', 'J1003.jpg', 'J1004.jpg', 'J1005.jpg', 'J1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\K\n",
      " Files (first 10): ['K1.jpg', 'K10.jpg', 'K100.jpg', 'K1000.jpg', 'K1001.jpg', 'K1002.jpg', 'K1003.jpg', 'K1004.jpg', 'K1005.jpg', 'K1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\L\n",
      " Files (first 10): ['L1.jpg', 'L10.jpg', 'L100.jpg', 'L1000.jpg', 'L1001.jpg', 'L1002.jpg', 'L1003.jpg', 'L1004.jpg', 'L1005.jpg', 'L1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\M\n",
      " Files (first 10): ['M1.jpg', 'M10.jpg', 'M100.jpg', 'M1000.jpg', 'M1001.jpg', 'M1002.jpg', 'M1003.jpg', 'M1004.jpg', 'M1005.jpg', 'M1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\N\n",
      " Files (first 10): ['N1.jpg', 'N10.jpg', 'N100.jpg', 'N1000.jpg', 'N1001.jpg', 'N1002.jpg', 'N1003.jpg', 'N1004.jpg', 'N1005.jpg', 'N1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\nothing\n",
      " Files (first 10): ['nothing1.jpg', 'nothing10.jpg', 'nothing100.jpg', 'nothing1000.jpg', 'nothing1001.jpg', 'nothing1002.jpg', 'nothing1003.jpg', 'nothing1004.jpg', 'nothing1005.jpg', 'nothing1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\O\n",
      " Files (first 10): ['O1.jpg', 'O10.jpg', 'O100.jpg', 'O1000.jpg', 'O1001.jpg', 'O1002.jpg', 'O1003.jpg', 'O1004.jpg', 'O1005.jpg', 'O1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\P\n",
      " Files (first 10): ['P1.jpg', 'P10.jpg', 'P100.jpg', 'P1000.jpg', 'P1001.jpg', 'P1002.jpg', 'P1003.jpg', 'P1004.jpg', 'P1005.jpg', 'P1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\Q\n",
      " Files (first 10): ['Q1.jpg', 'Q10.jpg', 'Q100.jpg', 'Q1000.jpg', 'Q1001.jpg', 'Q1002.jpg', 'Q1003.jpg', 'Q1004.jpg', 'Q1005.jpg', 'Q1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\R\n",
      " Files (first 10): ['R1.jpg', 'R10.jpg', 'R100.jpg', 'R1000.jpg', 'R1001.jpg', 'R1002.jpg', 'R1003.jpg', 'R1004.jpg', 'R1005.jpg', 'R1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\S\n",
      " Files (first 10): ['S1.jpg', 'S10.jpg', 'S100.jpg', 'S1000.jpg', 'S1001.jpg', 'S1002.jpg', 'S1003.jpg', 'S1004.jpg', 'S1005.jpg', 'S1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\space\n",
      " Files (first 10): ['space1.jpg', 'space10.jpg', 'space100.jpg', 'space1000.jpg', 'space1001.jpg', 'space1002.jpg', 'space1003.jpg', 'space1004.jpg', 'space1005.jpg', 'space1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\T\n",
      " Files (first 10): ['T1.jpg', 'T10.jpg', 'T100.jpg', 'T1000.jpg', 'T1001.jpg', 'T1002.jpg', 'T1003.jpg', 'T1004.jpg', 'T1005.jpg', 'T1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\U\n",
      " Files (first 10): ['U1.jpg', 'U10.jpg', 'U100.jpg', 'U1000.jpg', 'U1001.jpg', 'U1002.jpg', 'U1003.jpg', 'U1004.jpg', 'U1005.jpg', 'U1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\V\n",
      " Files (first 10): ['V1.jpg', 'V10.jpg', 'V100.jpg', 'V1000.jpg', 'V1001.jpg', 'V1002.jpg', 'V1003.jpg', 'V1004.jpg', 'V1005.jpg', 'V1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\W\n",
      " Files (first 10): ['W1.jpg', 'W10.jpg', 'W100.jpg', 'W1000.jpg', 'W1001.jpg', 'W1002.jpg', 'W1003.jpg', 'W1004.jpg', 'W1005.jpg', 'W1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\X\n",
      " Files (first 10): ['X1.jpg', 'X10.jpg', 'X100.jpg', 'X1000.jpg', 'X1001.jpg', 'X1002.jpg', 'X1003.jpg', 'X1004.jpg', 'X1005.jpg', 'X1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\Y\n",
      " Files (first 10): ['Y1.jpg', 'Y10.jpg', 'Y100.jpg', 'Y1000.jpg', 'Y1001.jpg', 'Y1002.jpg', 'Y1003.jpg', 'Y1004.jpg', 'Y1005.jpg', 'Y1006.jpg']\n",
      "\n",
      "Directory: data\\asl_alphabet_train\\asl_alphabet_train\\Z\n",
      " Files (first 10): ['Z1.jpg', 'Z10.jpg', 'Z100.jpg', 'Z1000.jpg', 'Z1001.jpg', 'Z1002.jpg', 'Z1003.jpg', 'Z1004.jpg', 'Z1005.jpg', 'Z1006.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Inspect the contents of your `data/` folder\n",
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"data\"):\n",
    "    print(f\"\\nDirectory: {root}\")\n",
    "    if dirs:\n",
    "        print(\" Subfolders:\", dirs)\n",
    "    if files:\n",
    "        print(\" Files (first 10):\", files[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656cec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84000 images across 28 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting landmarks: 100%|██████████| 84000/84000 [1:05:42<00:00, 21.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted landmarks for 63673 images (skipped 20327).\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 3: Extract A–Z plus ‘del’ & ‘space’ landmarks ─────────────────────────\n",
    "\n",
    "import os, cv2, numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = \"data/asl_alphabet_train/asl_alphabet_train\"\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    raise RuntimeError(f\"Train directory not found: {DATA_DIR}\")\n",
    "\n",
    "# Only include A–Z, or exactly 'del' or 'space'\n",
    "valid_labels = set(list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") + [\"del\", \"space\"])\n",
    "\n",
    "all_imgs = []\n",
    "for label in sorted(os.listdir(DATA_DIR)):\n",
    "    if label not in valid_labels:\n",
    "        continue\n",
    "    folder = os.path.join(DATA_DIR, label)\n",
    "    for fn in os.listdir(folder):\n",
    "        if fn.lower().endswith(\".jpg\"):\n",
    "            all_imgs.append((label, os.path.join(folder, fn)))\n",
    "\n",
    "print(f\"Found {len(all_imgs)} images across {len(valid_labels)} classes.\")\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "X, y = [], []\n",
    "for label, img_path in tqdm(all_imgs, desc=\"Extracting landmarks\"):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None: continue\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    res = hands.process(img_rgb)\n",
    "    if not res.multi_hand_landmarks: continue\n",
    "\n",
    "    lm = res.multi_hand_landmarks[0]\n",
    "    coords = []\n",
    "    for p in lm.landmark:\n",
    "        coords += [p.x, p.y, p.z]\n",
    "    X.append(coords)\n",
    "    y.append(label)\n",
    "\n",
    "hands.close()\n",
    "\n",
    "X = np.array(X, dtype=np.float32)\n",
    "y = np.array(y)\n",
    "print(f\"Extracted landmarks for {len(X)} images (skipped {len(all_imgs)-len(X)}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d6d275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (50938, 63) (50938,)\n",
      "Validation set: (12735, 63) (12735,)\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 4: Encode labels & split data ─────────────────────────────────────────\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)  # maps 'A'→0, …, 'Z'→25\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_int,\n",
    "    test_size=0.2,\n",
    "    stratify=y_int,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471bb4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'del' 'space']\n",
      "Train: (50938, 63) (50938,)\n",
      "Val:   (12735, 63) (12735,)\n",
      "Epoch 1/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4272 - loss: 2.0370 - val_accuracy: 0.8925 - val_loss: 0.4133\n",
      "Epoch 2/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8701 - loss: 0.4551 - val_accuracy: 0.9484 - val_loss: 0.2269\n",
      "Epoch 3/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9190 - loss: 0.2933 - val_accuracy: 0.9631 - val_loss: 0.1662\n",
      "Epoch 4/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9369 - loss: 0.2218 - val_accuracy: 0.9529 - val_loss: 0.1501\n",
      "Epoch 5/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9456 - loss: 0.1918 - val_accuracy: 0.9723 - val_loss: 0.1181\n",
      "Epoch 6/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1672 - val_accuracy: 0.9714 - val_loss: 0.1102\n",
      "Epoch 7/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1506 - val_accuracy: 0.9759 - val_loss: 0.1018\n",
      "Epoch 8/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9589 - loss: 0.1423 - val_accuracy: 0.9778 - val_loss: 0.0948\n",
      "Epoch 9/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9586 - loss: 0.1399 - val_accuracy: 0.9755 - val_loss: 0.0954\n",
      "Epoch 10/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.1330 - val_accuracy: 0.9686 - val_loss: 0.1102\n",
      "Epoch 11/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9631 - loss: 0.1289 - val_accuracy: 0.9754 - val_loss: 0.0949\n",
      "Epoch 12/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9641 - loss: 0.1200 - val_accuracy: 0.9761 - val_loss: 0.0887\n",
      "Epoch 13/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9656 - loss: 0.1182 - val_accuracy: 0.9775 - val_loss: 0.0921\n",
      "Epoch 14/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9672 - loss: 0.1127 - val_accuracy: 0.9807 - val_loss: 0.0774\n",
      "Epoch 15/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9677 - loss: 0.1107 - val_accuracy: 0.9740 - val_loss: 0.0926\n",
      "Epoch 16/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9669 - loss: 0.1084 - val_accuracy: 0.9833 - val_loss: 0.0695\n",
      "Epoch 17/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9679 - loss: 0.1036 - val_accuracy: 0.9821 - val_loss: 0.0709\n",
      "Epoch 18/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9683 - loss: 0.1055 - val_accuracy: 0.9837 - val_loss: 0.0692\n",
      "Epoch 19/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9691 - loss: 0.1034 - val_accuracy: 0.9804 - val_loss: 0.0723\n",
      "Epoch 20/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9715 - loss: 0.0942 - val_accuracy: 0.9742 - val_loss: 0.0861\n",
      "Epoch 21/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9720 - loss: 0.0971 - val_accuracy: 0.9847 - val_loss: 0.0648\n",
      "Epoch 22/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0938 - val_accuracy: 0.9821 - val_loss: 0.0652\n",
      "Epoch 23/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9723 - loss: 0.0957 - val_accuracy: 0.9830 - val_loss: 0.0648\n",
      "Epoch 24/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9721 - loss: 0.0930 - val_accuracy: 0.9811 - val_loss: 0.0741\n",
      "Epoch 25/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0951 - val_accuracy: 0.9819 - val_loss: 0.0651\n",
      "Epoch 26/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9716 - loss: 0.0928 - val_accuracy: 0.9853 - val_loss: 0.0614\n",
      "Epoch 27/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9728 - loss: 0.0896 - val_accuracy: 0.9823 - val_loss: 0.0670\n",
      "Epoch 28/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9706 - loss: 0.0953 - val_accuracy: 0.9849 - val_loss: 0.0604\n",
      "Epoch 29/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9747 - loss: 0.0861 - val_accuracy: 0.9854 - val_loss: 0.0571\n",
      "Epoch 30/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9743 - loss: 0.0847 - val_accuracy: 0.9807 - val_loss: 0.0714\n",
      "Epoch 31/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9760 - loss: 0.0822 - val_accuracy: 0.9853 - val_loss: 0.0592\n",
      "Epoch 32/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9749 - loss: 0.0823 - val_accuracy: 0.9849 - val_loss: 0.0560\n",
      "Epoch 33/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9727 - loss: 0.0906 - val_accuracy: 0.9863 - val_loss: 0.0546\n",
      "Epoch 34/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.0795 - val_accuracy: 0.9865 - val_loss: 0.0547\n",
      "Epoch 35/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.0797 - val_accuracy: 0.9870 - val_loss: 0.0497\n",
      "Epoch 36/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.0794 - val_accuracy: 0.9865 - val_loss: 0.0543\n",
      "Epoch 37/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9753 - loss: 0.0790 - val_accuracy: 0.9863 - val_loss: 0.0531\n",
      "Epoch 38/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9760 - loss: 0.0769 - val_accuracy: 0.9863 - val_loss: 0.0526\n",
      "Epoch 39/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9745 - loss: 0.0813 - val_accuracy: 0.9854 - val_loss: 0.0561\n",
      "Epoch 40/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0744 - val_accuracy: 0.9865 - val_loss: 0.0517\n",
      "Epoch 41/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0770 - val_accuracy: 0.9869 - val_loss: 0.0531\n",
      "Epoch 42/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9766 - loss: 0.0776 - val_accuracy: 0.9862 - val_loss: 0.0534\n",
      "Epoch 43/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9778 - loss: 0.0711 - val_accuracy: 0.9870 - val_loss: 0.0517\n",
      "Epoch 44/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9768 - loss: 0.0714 - val_accuracy: 0.9833 - val_loss: 0.0586\n",
      "Epoch 45/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9774 - loss: 0.0730 - val_accuracy: 0.9878 - val_loss: 0.0483\n",
      "Epoch 46/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9779 - loss: 0.0689 - val_accuracy: 0.9717 - val_loss: 0.0840\n",
      "Epoch 47/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0695 - val_accuracy: 0.9879 - val_loss: 0.0500\n",
      "Epoch 48/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9789 - loss: 0.0676 - val_accuracy: 0.9883 - val_loss: 0.0453\n",
      "Epoch 49/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9785 - loss: 0.0687 - val_accuracy: 0.9860 - val_loss: 0.0537\n",
      "Epoch 50/50\n",
      "\u001b[1m1592/1592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9781 - loss: 0.0707 - val_accuracy: 0.9834 - val_loss: 0.0529\n"
     ]
    }
   ],
   "source": [
    "# ── Cell 5: Build & train the MLP with dynamic output size ────────────────────\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Encode labels and discover number of classes\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)        # maps your strings → integers 0…27\n",
    "num_classes = len(le.classes_)     # should be 28\n",
    "print(\"Classes found:\", le.classes_)\n",
    "\n",
    "# 2) Split into train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_int,\n",
    "    test_size=0.2,\n",
    "    stratify=y_int,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:  \", X_val.shape,   y_val.shape)\n",
    "\n",
    "# 3) Build your MLP with the right number of outputs\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(63,)),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(num_classes, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 4) Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be15adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: asl_alphabet_mlp.h5  and  label_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "model.save(\"asl_alphabet_mlp.h5\")\n",
    "\n",
    "import pickle\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print(\"Saved: asl_alphabet_mlp.h5  and  label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "with open(\"asl_alphabet_full.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
